entrypoint: mnist_st.py
name: first- 
gpusPerTrial: 0
maxGpus: 0
requirements: requirements.txt
# gpuTypes:
#   - K80

useSpot: false
cuda: 11.3

# codeTransfer:
#   type: GITHUB_PRIVATE
#   repo: git@github.com:k4rth33k/code_bunker.git
#   commit: a2b761415f057c7f76db68ff3ca2403e3358d324
#   credentials:
#     GITHUB_PAT: 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

minvCPUs: 8
minMemory: 16
maxCPUWorkers: 3

visualisation:
  type: AIM
  startWithJob: True

# customImage:
#   image: ubuntu:18.04
  # credentials:
  #   registry: your_registry
  #   username: username
  #   password: pass

cloudProviders: 
 - name: AWS
   regions:
    - us-east-1
  
#  - name: AZURE
#    regions:
#     - southcentralus

#  - name: GCP
#    regions:
#     - us-central1


environment:
  ST_PLATFORM_API: http://platform-api-loadbalancer-1708204133.us-east-1.elb.amazonaws.com

maxCost: 50
maxTime: 1h25m

# preJobCommands:
#   - apt-get update -y
#   - apt-get install nano

# postJobCommands:
#   - curl --upload-file ./your-file.txt https://free.keep.sh 

# sweep:
#   searchSpace:
#     batch_size:
#       type: choice
#       value: [16, 32, 64, 128]
#     hidden_size:
#       type: choice
#       value: [128, 256, 512, 1024]
#     lr:
#       type: choice
#       value: [0.0001, 0.001, 0.01, 0.1]
#     momentum:
#       type: uniform
#       value: [0, 1]

#   tuner:                          
#     name: TPE                                     
#     optimizeMode: maximize     

experiment:
  args:
    batch_size: [16, 32]
    hidden_size: [128, 256]
    lr: [0.0001, 0.001, 0.01, 0.1]
